xpathSApply(doc, "//*/div[@class='relationBox']", xmlValue)
xpathSApply(doc, "//*/div[@class='name']", xmlValue)
?xpathSApply
?xpathSApply
table(unlist(sapply(doc["//*|//text()|//comment()|//processing-instruction()"],
class)))
xpathSApply(doc, "//*/div[@class='name']", xmlValue)
xpathSApply(doc, "//*/div[@class='relationBox'][2]", xmlValue)
c <- xpathSApply(doc, "//*/div[@class='relationBox']", xmlValue)
c <- xpathSApply(doc, "//*/div[@class='relationBox'][2]", xmlValue)
c <- xpathSApply(doc, "//*/div[@class='relationBox']", xmlValue)
xpathSApply(doc,"//*/div[@class='relationBox']/text()")
xpathSApply(doc,"//*/div[@class='relationBox']")
c <- xpathSApply(doc,"//*/div[@class='relationBox']")
c[1]
c <- xpathSApply(doc,"//*/div[@class='relationBox']")
c <- xpathSApply(doc,"//*/div[@class='relationBox']/text()")
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='name']",xmlValue)
c <- xpathSApply(doc,"//*/div",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='name']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='name']")
c <- xpathSApply(doc,"//*/div[@class='relationBox']")
d <- xpathSApply(c,"//*/div")
d <- xpathSApply(c,"//*/div/",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue,' ')
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue & ' ')
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue())
c <- xpathSApply(doc,"//*/div[@class='relationBox']/text()")
c <- xpathSApply(doc,"//*/div[@class='relationBox']/text")
c <- xpathSApply(doc,"//*/div[@class='relationBox']/")
c <- xpathSApply(doc,"//*/div[@class='relationBox']")
d <- xpathSApply(c,"//*/div[@class='name']")
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue)
c <- unlist(xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue))
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue())
c <- xpathSApply(doc,"//*/div[@class='relationBox']")
c <- xpathSApply(doc,"//*/div[@class='relationBox']",)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlValue)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlValue(xmlChildren(x)$name))
c <- xpathSApply(doc,"//*/div[@class='relationBox']")
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue " ")
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue(" "))
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='name']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='name']",function(x) xmlValue)
c <- xpathSApply(doc,"//*/div[@class='name']",function(x) xmlValue(x))
c <- xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlValue(x))
c <- xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlValue(x)+' ')
c <- xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlValue(x)' ')
c <- xpathSApply(doc,"//*/div[@class='name']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlName)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue,xmlName)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",xmlValue,xmlName)
c <- xpathSApply(doc,"//*/div[@class='name']",function(x) xmlValue(x))
c <- xpathSApply(doc,"//*/div[@class='relationBox']",function(x) c(xmlValue(x)," "))
View(c)
c <- xpathSApply(doc,"//*/div[@class='relationBox']",function(x) c(xmlValue(x))
)
c <- xpathSApply(doc,"//*/div[@class='name']",function(x) xmlValue(x))
c <- xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlValue(x))
c <- data.frame(xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlValue(x)))
View(c)
c <- data.frame(xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlNode(x)))
c <- data.frame(xpathSApply(doc,"//*/div[@class='relationBox']",function(x) xmlNode(x)))
txt <- xpathApply(doc, "//body//text()[not(ancestor::script)][not(ancestor::style)][not(ancestor::noscript)]", xmlValue)
cat(unlist(txt))
txt <- xpathApply(doc, "//div//text()[not(ancestor::script)][not(ancestor::style)][not(ancestor::noscript)]", xmlValue)
cat(unlist(txt))
txt <- xpathApply(doc, "//div//text()[@class="relationBox]", xmlValue)
cat(unlist(txt))
txt <- xpathApply(doc, "//div[@class="relationBox]", xmlValue)
cat(unlist(txt))
txt <- xpathApply(doc, "//div[@class="relationBox]", xmlValue)
txt <- xpathApply(doc, "//div[@class="relationBox""]", xmlValue)
txt <- xpathApply(doc, "//div[@class='relationBox']", xmlValue)
library(XML)
# Read and parse HTML file
doc.html = htmlTreeParse('http://investing.businessweek.com/research/stocks/people/people.asp?ticker=UNP',
useInternal = TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all \n by spaces
doc.text = gsub('\\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
doc.text = paste(doc.text, collapse = ' ')
x <- xpathApply(doc.html, "//table/tr")
x
sapply(x,xmlValue)
library(XML)
theurl <- "http://investing.businessweek.com/research/stocks/people/people.asp?ticker=UNP"
tables <- readHTMLTable(theurl)
n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))
tables[1]
tables[2]
tables[3]
tables[4]
tables[5]
tables[6]
library(XML)
theurl <- "http://investing.businessweek.com/research/stocks/people/people.asp?ticker=UNP"
tables <- readHTMLTable(theurl)
tables[1]
tables[2]
t <- tables[2]
d <- data.frame[t]
d <- data.frame(t)
View(d)
library(xml)
library(XML)
tables <- readHTMLTable("http://investing.businessweek.com/research/stocks/people/people.asp?ticker=CP:CN")
t <- tables[1]
?readHTMLTable
tables <- readHTMLTable("http://investing.businessweek.com/research/stocks/people/people.asp?ticker=CP:CN",header=TRUE)
df <- data.frame(tables[1])
View(df)
df <- data.frame(tables[2])
View(df)
tables <- readHTMLTable("http://investing.businessweek.com/research/stocks/people/people.asp?ticker=CP:CN",header=TRUE,skip=1)
df <- data.frame(tables[2])
View(df)
View(df)
str(tables)
View(c)
?XML
??XML
?getLinks
library(XML)
url <- "http://investing.businessweek.com/research/stocks/people/people.asp?ticker=CP:CN"
doc <- htmlTreeParse(url,useInternal=TRUE)
tables <- readHTMLTable(doc,header=TRUE,skip=1)
str(doc)
?htmlTreeParse
library(XML)
url <- "http://investing.businessweek.com/research/stocks/people/people.asp?ticker=CP:CN"
url <- "http://investing.businessweek.com/research/stocks/people/relationship.asp?personId=353022&ticker=CP:CN"
doc <- htmlTreeParse(url,useInternal=TRUE)
tables <- readHTMLTable(doc,header=TRUE,skip=1)
df <- data.frame(tables[1])
View(df)
df <- data.frame(tables[2])
View(df)
df <- data.frame(tables[3])
View(df)
df <- data.frame(tables[4])
View(df)
txt <- xpathSApply(doc, "//div[@class='relationBox']", xmlValue)
txt <- xpathSApply(doc, "//div[@class='name']", xmlValue)
df <- data.frame(txt)
View(df)
txt <- xpathSApply(doc, "//div[@class='relationBox']/", function (x) {xmlValue(x)})
txt <- xpathSApply(doc, "//div[@class='relationBox']/", function (x) xmlValue(x))
txt <- xpathSApply(doc, "//div[@class='relationBox']/", function(x) xmlValue(x))
txt <- xpathSApply(doc, "//div[@class='relationBox']", function(x) xmlValue(x))
txt <- xpathSApply(doc, "//div/a", function(x) xmlValue(x))
txt <- xpathSApply(doc, "//div/a")
df <- data.frame(txt)
df <- data.frame(txt[1])
txt <- xpathSApply(doc, "//div/a", xmlValue)
df <- data.frame(txt[1])
df <- data.frame(txt)
View(df)
txt <- xpathSApply(doc, "//div/a", @href)
txt <- xpathSApply(doc, "//div/a/@href", xmlValue)
txt <- xpathSApply(doc, "//div/a@href", xmlValue)
links <- xpathSApply(doc, "//a/@href")
str(links)
library(XML)
url <- "http://investing.businessweek.com/research/stocks/people/people.asp?ticker=CP:CN"
url <- "http://investing.businessweek.com/research/stocks/people/relationship.asp?personId=353022&ticker=CP:CN"
doc <- htmlTreeParse(url,useInternal=TRUE)
tables <- readHTMLTable(doc,header=TRUE,skip=1)
links <- xpathSApply(doc, "//a/@href")
df <- data.frame(links)
View(df)
View(c)
View(df)
library(XML)
url <- "http://investing.businessweek.com/research/stocks/people/people.asp?ticker=CP:CN"
url <- "http://investing.businessweek.com/research/stocks/people/relationship.asp?personId=353022&ticker=CP:CN"
doc <- htmlTreeParse(url,useInternal=TRUE)
tables <- readHTMLTable(doc,header=TRUE,skip=1)
links <- xpathSApply(doc, "//div[@class='name']/a/@href")
df <- data.frame(links)
View(df)
library(XML)
url <- "http://investing.businessweek.com/research/stocks/people/people.asp?ticker=CP:CN"
url <- "http://investing.businessweek.com/research/stocks/people/relationship.asp?personId=353022&ticker=CP:CN"
doc <- htmlTreeParse(url,useInternal=TRUE)
tables <- readHTMLTable(doc,header=TRUE,skip=1)
allLinks <- xpathSApply(doc, "//a/@href")
nameLinks <- xpathSApply(doc, "//div[@class='name']/a/@href")
df <- data.frame(allLinks)
df1 <- data.frame(nameLinks)
View(df1)
library(igraph)
g <- graph(c("a","b"))
?igraph
relations <- data.frame(from=c("Bob", "Cecil", "Cecil", "David",
"David", "Esmeralda"),
to=c("Alice", "Bob", "Alice", "Alice", "Bob", "Alice"),
same.dept=c(FALSE,FALSE,TRUE,FALSE,FALSE,TRUE),
friendship=c(4,5,5,2,1,1), advice=c(4,5,5,4,2,3))
g <- graph.data.frame(relations, directed=TRUE, vertices=actors)
print(g, e=TRUE, v=TRUE)
actors <- data.frame(name=c("Alice", "Bob", "Cecil", "David",
"Esmeralda"),
age=c(48,33,45,34,21),
gender=c("F","M","F","M","F"))
g <- graph.data.frame(relations, directed=TRUE, vertices=actors)
print(g, e=TRUE, v=TRUE)
plot(g)
g["Bob","Esmeralda"]
test.graph
g
require(igraph)
G<-graph.data.frame(as.data.frame(cbind(id1=c(1,1,2,3,1,4),id2=c(2,3,4,4,5,5),weight=c(0.5,0.35,0.5,0.9,0.6,0.6))), directed=FALSE)
plot(G, edge.label=paste(E(G),"=",signif(E(G)$weight, digits=1)), vertex.size=10)
#weighted shortest path using connection probability
a<-get.shortest.paths(G,1,4, weights=E(G)$weight, output="epath")[[1]]
E(G)[a]
prod(E(G)$weight[a])
#weighted shortest path using the inverse of connection probability
b<-get.shortest.paths(G,1,4, weights=1-E(G)$weight, output="epath")[[1]]
E(G)[b]
prod(E(G)$weight[b])
getwd()
setwd("C:/Users/John/Desktop/data")
dir()
setwd("C:/Users/John/Desktop/data/"UCI HAR Dataset"")
setwd("C:/Users/John/Desktop/data/UCI HAR Dataset)
""
)
)
""
setwd("C:/Users/John/Desktop/data/UCI HAR Dataset")
getwd()
dir()
#
#  run_analysis.R
# Performs the following:
# 1.Merges the training and the test sets to create one data set.
# 2.Extracts only the measurements on the
#   mean and standard deviation for each measurement.
# 3.Uses descriptive activity names to name the activities
#   in the data set
# 4.Appropriately labels the data set with descriptive variable names.
# 5.From the data set in step 4, creates a second,
#   independent tidy data set with the average of each variable
#   for each activity and each subject.
#
# Get activity labels
activity <- read.table("activity_labels.txt")
# Get feature labels
features <- read.table("features.txt")
# Combine subject train and test
subject_test <- read.table("test/subject_test.txt")
subject_train <- read.table("train/subject_train.txt")
subject <- rbind(subject_test, subject_train)
remove(subject_test)
remove(subject_train)
# Combine X train and test
X_test <- read.table("test/X_test.txt")
X_train <- read.table("train/X_train.txt")
X <- rbind(X_test, X_train)
remove(X_test)
remove(X_train)
# Combine y train and test
y_test <- read.table("test/y_test.txt")
y_train <- read.table("train/y_train.txt")
y <- rbind(y_test, y_train)
remove(y_test)
remove(y_train)
# merge into one dataset
z <- cbind(subject, y, X)
remove(subject)
remove(X)
remove(y)
# label all columns
c <- paste(features$V2)
colnames(z) <- c("Subject","Activity",c)
# select only mean and standard deviation columns
c <- c[grepl("mean[:(:][:):]|std[:(:][:):]", c)]
z <- z[,c("Subject","Activity",c)]
remove(c)
#
#
#
merge(activity,z,by.x="V1",by.y="Activity",all=TRUE)
write.table(z,file="avg_by_activity_and_subject.txt",row.name=FALSE)
m <- merge(activity,z,by.x="V1",by.y="Activity",all=TRUE)
head(m)
View(m)
?merge
activity <- read.table("activity_labels.txt")
colnames(activity) <- c("ActivityID","Activity")
View(activity)
#
#  run_analysis.R
# Performs the following:
# 1.Merges the training and the test sets to create one data set.
# 2.Extracts only the measurements on the
#   mean and standard deviation for each measurement.
# 3.Uses descriptive activity names to name the activities
#   in the data set
# 4.Appropriately labels the data set with descriptive variable names.
# 5.From the data set in step 4, creates a second,
#   independent tidy data set with the average of each variable
#   for each activity and each subject.
#
# Get activity labels
activity <- read.table("activity_labels.txt")
colnames(activity) <- c("ActivityID","Activity")
# Get feature labels
features <- read.table("features.txt")
# Combine subject train and test
subject_test <- read.table("test/subject_test.txt")
subject_train <- read.table("train/subject_train.txt")
subject <- rbind(subject_test, subject_train)
remove(subject_test)
remove(subject_train)
# Combine X train and test
X_test <- read.table("test/X_test.txt")
X_train <- read.table("train/X_train.txt")
X <- rbind(X_test, X_train)
remove(X_test)
remove(X_train)
# Combine y train and test
y_test <- read.table("test/y_test.txt")
y_train <- read.table("train/y_train.txt")
y <- rbind(y_test, y_train)
remove(y_test)
remove(y_train)
# merge into one dataset
z <- cbind(subject, y, X)
remove(subject)
remove(X)
remove(y)
# label all columns
c <- paste(features$V2)
colnames(z) <- c("Subject","ActivityID",c)
# select only mean and standard deviation columns
c <- c[grepl("mean[:(:][:):]|std[:(:][:):]", c)]
z <- z[,c("Subject","ActivityID",c)]
remove(c)
#
#
#
m <- merge(activity,z,all=TRUE)
remove(z)
#
write.table(m,file="avg_by_activity_and_subject.txt",row.name=FALSE)
c <- paste(features$V2)
c <- c[grepl("mean[:(:][:):]|std[:(:][:):]", c)]
grp_m <- melt(m,id=c("ActivityID","Activity","Subject"),measure.vars=c))
grp_m <- melt(m,id=c("ActivityID","Activity","Subject"),measure.vars=c)
?melt
librry(reshape)
library(reshape)
install.packages("reshape")
grp_m <- melt(m,id=c("ActivityID","Activity","Subject"),measure.vars=c)
library(reshape)
grp_m <- melt(m,id=c("ActivityID","Activity","Subject"),measure.vars=c)
View(grp_m)
?dcast
library(reshape)
?dcast
?cast
dcast(grp_m, Subject + Activity + ActivityID ~ variable, mean)
cast(grp_m, Subject + Activity + ActivityID ~ variable, mean)
cast_m <- cast(grp_m, Subject + Activity + ActivityID ~ variable, mean)
View(cast_m)
View(cast_m)
getwd()
setwd("C:/Users/John/Documents")
install.packages("twitteR")
rdmTweets <- searchTwitter("Rairoad",n=5,lang="en")
?twitteR
library(twitteR)
rdmTweets <- searchTwitter("Rairoad",n=5,lang="en")
getTWitterOAuth()
?readHTML
library(XML)
?readHTML
t <- readHTMLTable("http://www.up.com")
t <- readHTMLTable("http://www.papproth.com")
t <- readHTMLTable("http://www.railroadpm.com")
t <- readHTMLTable("http://www.google.com")
t <- readHTMLTable("http://www.bing.com")
t[1]
t[2]
t[[1]
]
t <- readHTMLTable("http://www.railroadpm.org/home/RPM/Performance%20Reports/UP.aspx")
t[1]
t[2]
t[3]
t[4]
t1 <- t[1]
t2 <- t[2]
t3 <- t[3]
t4 <- t[4]
t5 <- t[5]
t6 <- t[6]
df <- data.frame(t1)
View(df)
df <- data.frame(t2)
View(df)
df <- data.frame(t3)
View(df)
df <- data.frame(t4)
View(df)
df <- data.frame(t5)
View(df)
df <- data.frame(t6)
View(df)
df6 <- readHTMLTable("http://www.railroadpm.org/home/RPM/Performance%20Reports/UP.aspx")[6]
rm(df6)
df6 <- data.frame(readHTMLTable("http://www.railroadpm.org/home/RPM/Performance%20Reports/UP.aspx")[6])
View(df6)
t <- readHTMLTable("http://investing.businessweek.com/research/stocks/people/person.asp?personId=310128&ticker=UNP")
t.length
t.size()
t.size
size(t)
length(t)
for (i in 1:length(t)) print i;
for (i in 1:length(t)) (print i);
for (i in 1:length(t)) print(i)
for (i in 1:length(t)) { print(i); }
for (i in 1:length(t)) { assign(paste0("Variable",i),i) }
for (i in 1:length(t)) { assign(paste0("df",i),data.frame(t[i]) }
for (i in 1:length(t)) { assign(paste0("df",i),data.frame(t[i])) }
View(df2)
View(df3)
View(df4)
View(df5)
View(df6)
install.packages("svd")
install.packages("RTextTools")
library(RTextTools)
library(topicmodels)
data(NYTimes)
View(NYTimes)
data <- NYTimes[sample(1:3100,size=1000,replace=FALSE),]
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),language="english")
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),language="english",removeNumbers=TRUE,stemWords=TRUE,weighting=weightTf)
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),language="english",removeNumbers=TRUE,stemWords=TRUE,weighting=weightTf)
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),language="english",removeNumbers=TRUE,stemWords=TRUE,weighting=weightTf)
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),language="english",removeNumbers=TRUE,stemWords=TRUE,weighting=weighTf)
?create_matrix
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),language="english",removeNumbers=TRUE,stemWords=TRUE,weighting=weighTf)
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),language="english",removeNumbers=TRUE,stemWords=TRUE,weighting=tm::weightTfIdf)
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),language="english",removeNumbers=TRUE,stemWords=TRUE,weighting=tm::weightTf)
k <- length(unique(data$Topic.Code))
lda <- LDA(matrix,k)
tersm(lda)
terms(lda)
topics(lda)
View(data)
?LDA
lda <- LDA(matrix,1000)
install.packages("quantmod")
library(quantmod)
getfinancials('UNP')
getFinancials('UNP')
viewFinancials('UNP',f)
viewFinancials(UNP.f)
getFinancials('BRK.A')
getFinancials('BRK.B')
viewFinancials(BRK.A.f)
?quantmod
getSymbols.google
getSymbols.google('UNP')
getSymbols('UNP')
View(UNP)
tail(UNP)
plot(UNP.Open)
plot(UNP.UNP.Open)
plot(UNP)
summary(UNP)
?plot
names(UNP)
plot(UNP$row.names,UNP$UNP.Open)
plot(UNP$UNP.Open)
plot(UNP$UNP.High)
plot(UNP$UNP.Low)
UNP.f[1]
UNP.f[2]
UNP.f[3]
install.packages("tm.plugin.webmining")
library(tm)
library(tm.plugin.webmining)
googlenews <- WebCorpus(GoogleNewsSource("UNP"))
head(googlenews)
GoogleNewsSource("Railroad")
news< - GoogleNewsSource("Railroad")
news <- GoogleNewsSource("Railroad")
df <- data.frame(news)
rm(list=ls())
setwd("C:\Users\John\Documents\GitHub\RepData_PeerAssessment1")
setwd("C:/Users/John/Documents/GitHub/RepData_PeerAssessment1")
dir()
dir()
